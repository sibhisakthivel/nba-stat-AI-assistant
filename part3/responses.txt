##### Part 3: Writeup

Answer the questions listed in the Part 3 section of Submission Requirements. Do NOT use any AI tools for this section. Limit each response to 500 words or fewer.

1. My approach to part 1 focused on understanding how data flowed from ingestion to retrieval and optimizing each step to improve response accuracy while maintaining speed.
Before this project, I’d never built anything involving RAG or NLP, so I began by studying each backend file to understand its purpose. I spent time learning about vector 
embeddings and retrieval pipelines, which helped me avoid inefficient embedding and extraction methods. 

Once I had a solid foundation, I focused on improving the row embedding process. I realized that aligning row embeddings with question embeddings would be much easier if 
I utilized details from other tables, not just the table I was currently embedding. My goal was to make the row text as informative yet minimal as possible to prevent 
unnecessary words from impacting embedding alignment.

While implementing rag.py, I faced extremely long Ollama runtimes. After testing, I identified two main causes: overly long context prompts and limited hardware capacity. 
After condensing context length and freeing up system resources, response speed improved significantly.

My initial retrieval accuracy was strong, as I was able to answer most of the 10 provided questions correctly. The main questions I had trouble with were the
"leading scorer" questions. I observed that although I was retriving the correct game_details rows, I wasn't retrieving enough player_box_scores rows to ensure that 
the leading scorer was included among them. I debated between embedding “leader” tags versus expanding retrieval for those "leader" type questions, and decided to implement 
the latter for a cleaner design, trading slightly slower responses for much higher accuracy. Question 10 was another edge case due to date phrasing. I addressed it by including 
a date phrase in the embedding that mirrored the format used in the question.

Prompt engineering was iterative but relatively straightforward. I refined prompts to clarify the LLM's misunderstandings and enforce output formatting consistency.

For Part 2, I had no prior frontend experience, so adapting to Angular was initially challenging. After exploring the repo structure, I really enjoyed designing and implementing 
the chat interface. This was something that I’ve been meaning to implement into my own NBA data project, so feature ideas came naturally. It was also an interesting experience
learning how to establish and debug the frontend-backend connection.

In summary, I completed this project using an end-to-end optimization approach. I familiarized myself with, refined, and connected each component until the system performed 
reliably. This approach helped me transform a set of unfamiliar tools into an effective, efficient pipeline.



2. My technical skillset is centered on predictive modeling and data analysis/visualization using machine learning and deep learning frameworks, and statistical modeling 
techniques. My work also requires proficiency in data handling, cleaning, and filtering using SQL. My experience with this (especially working with NBA game and player data in my 
own projects) allowed me to come into this project with deep understanding of the tables and data I was provided, and to naturally identify how I could optimally utilize this 
data to improve the RAG, embedding, and backend pipelines.

Additionally, my prior experience developing a multi-agent LLM system also prepared me for this project’s prompt engineering and output control challenges. Through that project, 
I became comfortable analyzing how models interpret instructions, identifying sources of error or misalignment, and iteratively adjusting prompts to improve reliability. It also 
taught me how to handle unwanted or inconsistent responses by adding structural constraints, refining contextual phrasing, or reordering system instructions to guide the model toward 
consistent and accurate outputs. These skills transferred directly to this project, especially when tuning prompts for retrieval reasoning and output formatting.

This project taught me how to design NLP applications through RAG pipelines and gave me a clearer understanding of how embedding vectors are created, stored, and retrieved 
for contextual reasoning. It also exposed me to new areas of software development, such as integrating backend systems with a frontend interface, which helped strengthen my 
full-stack engineering foundation. I also learned more about how local LLMs operate, the limitations my machine imposes on them, and how to manage the resulting long runtimes. 
During these challenges, I adapted by  parsing each question to dynamically adjust the context size, ensuring faster responses without including unnecessary data or irrelevant context.

Moving forward, I hope to deepen my understanding of the techniques I implemented in this project, particularly RAG pipelines, embedding optimization, and efficient context retrieval. 
I plan to apply these skills to my NBA player performance modeling work by deploying and benchmarking LLMs in a production-like environment to automate and scale insight generation.
I also want to explore how these same techniques can be optimized for larger, more complex datasets and more challenging retrieval contexts.



3. Sub-possession level data shows on how teams carry out individual plays, providing specific insights on player movement patterns, decision timing, and spacing. This data is valuable as 
analyzing it allows us to determine several features that impact in-game strategy decisions.

I would start by analyzing opponent data to identify which play types they run most frequently and which they find the most success with. This would enable the team to anticipate the 
opponent's preferred play set and adjust their defensive setup accordingly. I would also identify which positional and spacing setups typically result in unsuccessful possessions, which
would guide the defense to try to force their opponents into these inefficient schemas.

Next I would analyze my own team's data. I would identify which play types and positional setups have been reliably successful, and which have been historically unsuccessful. Not only would 
this impact in-game strategic decision-making, but it would also allow the coaching staff to identify areas of weakness to focus on during practice. Furthermore, when taking into account common
play types that specific opponents struggle defending against, we could adjust our offensive game plan to exploit those weaknesses to maximize scoring output.

Finally, I would use this data to explore individual player success from specific positions or in specific roles within a play. Not only would this identify how a player can be used optimally on the
court in a game, but it would highlight areas of weakness to prioritize during practice.



4. This deeply detailed player positional tracking data provides a perspective on the game that traditional statistics and tracking systems cannot capture. By transforming this data into 
interpretable performance metrics, we can generate insights that inform player development, injury prevention, and in-game strategic decision-making.

The first feature I'd implement would focus on identifying movement patterns that suggest an incoming injury. I'd analyze the historical data to recognize movement patterns that have been observed 
prior to injury instances, such as degraded posture, reduced movement speed, or delayed reaction time. By comparing these pre-injury patterns with baseline healthy movement sequences, I could 
isolate movement indicators that signal elevated injury risk. I would model this using a sequence-based deep learning architecture such as an LSTM, which would recognize changes in movement pattern 
within the large-scale dataset. I would utilize Spark for data preprocessing and feature extraction, and perform model training and evaluation through PyTorch. The model would output an injury risk 
rating for each major joint of each modeled player. This feature would allow the medical team to take precautions and adjust recovery practices for each player accordingly.

The second feature I’d implement would focus on detecting and quantifying player fatigue in real time based on changes in movement quality. I would analyze patterns such as increased stance height, 
slower lateral reactions, and reduced arm extension during defensive contests. By monitoring these changes over time and comparing them to baseline movement behavior from the beginning of games, 
a model could identify early signs of fatigue before it reaches a point where a player negatively affects the game. I would model this using sliding window sequence analysis to capture short-term 
changes in movement behavior, while Spark would manage the large-scale streaming data and PyTorch would handle model training and inference. The model would output a fatigue rating for each player 
that updates dynamically throughout the game. This feature would allow coaches to make informed substitution decisions, optimize rotation timing, and track conditioning progress throughout the season.

The third feature I'd implement would rate a player's ability to create space on offense or close space as a defender. I would analyze the data to measure relative positioning between offensive and 
defensive players. On offense, these metrics would demonstrate how effectively a player creates separation from defenders, and on defense, they would measure a player's ability to stay in front of their
opponent while keeping pressure on them and preventing positional advancement. I would model these interactions using spatial-temporal analysis techniques to track how spacing changes across possessions.
Spark would be used for large-scale data processing, and PyTorch would handle model training and evaluation. The model would output a “space efficiency” rating for each player's offense and defense, 
allowing coaches to evaluate matchups, lineup fit, and individual player movement tendencies. 



5. The goal of this system would be to transform a large text corpus into actionable insights for Basketball Operations. I would design an end-to-end NLP pipeline that organizes, interprets, and delivers 
information to front-office staff in a clear and readable format. This system would convert unstructured reports and notes into structured knowledge, allowing decision-makers to efficiently access and 
interpret incoming data. 

I would start by building a data-ingestion pipeline to organize the different document types within the corpus. Text from PDFs, emails, and spreadsheets would be extracted using tools such as PyPDF2. 
Each document would then be tagged with labels such as author, date, document type, and source reliability to preserve context. Once processed, the text would be embedded using OpenAI’s text-embedding 
models, allowing for similarity-based retrieval even when tone and diction differ across reports. This representation ensures that both subjective evaluations and structured information can be efficiently 
compared and retrieved through a query-driven system.

Once the data is embedded and stored, I would develop a retrieval and analysis system that allows users to efficiently access relevant insights from the corpus. I would perform data retrieval through
a combination of vector similarity and keyword filtering for specific names, teams, or dates. This ensures that both contextually similar and explicitly referenced documents are returned for any given query.
The retrieved content would then be provided to an LLM for reformatting, while still maintaing diverse perspectives in subjective reports. This step would allow the model to highlight consensus among
sources, identify conflicting evaluations, and other key details that would influence decision-making.

To ensure reliability, I would implement a validation check that cross-references LLM outputs with their cited sources to verify accuracy. Outputs flagged for low confidence, missing citations, or 
conflicting information would be routed for manual review by analysts, creating a feedback loop that strengthens model performance over time. This validation step would help the front office develop 
confidence in the system’s findings and rely on it as a consistent decision-support tool. Over time, this process would refine the system’s accuracy and improve its ability to interpret data and support 
organizational decision-making.
